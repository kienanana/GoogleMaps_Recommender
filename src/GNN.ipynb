{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    }
   ],
   "source": [
    "import os, math, time, random, sys, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = (torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "          else (torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "                else torch.device(\"cpu\")))\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:7: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:9: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True))\n",
      "/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_65547/1163633578.py:9: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  chunks.append(pd.read_json('\\n'.join(chunk), lines=True))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411496, 6) (3721, 15)\n"
     ]
    }
   ],
   "source": [
    "def read_json_in_chunks(file_path, chunk_size=10000):\n",
    "    chunks, chunk = [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            chunk.append(line)\n",
    "            if (i + 1) % chunk_size == 0:\n",
    "                chunks.append(pd.read_json('\\n'.join(chunk), lines=True)); chunk = []\n",
    "        if chunk:\n",
    "            chunks.append(pd.read_json('\\n'.join(chunk), lines=True))\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "reviews_path = \"../data/processed/sf-sampled-reviews.json\"\n",
    "items_path   = \"../data/processed/sf-restaurants.json\"\n",
    "\n",
    "reviews_df   = read_json_in_chunks(reviews_path)\n",
    "items_df     = read_json_in_chunks(items_path)\n",
    "\n",
    "assert {'user_id','gmap_id','time'}.issubset(reviews_df.columns)\n",
    "assert {'gmap_id','avg_rating','num_of_reviews','price'}.issubset(items_df.columns)\n",
    "print(reviews_df.shape, items_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (224017, 6) test: (75747, 6)\n"
     ]
    }
   ],
   "source": [
    "def chrono_split_per_user(df, train_ratio=0.8, min_hist=3):\n",
    "    df = df.sort_values(by=['user_id','time'])\n",
    "    train, test = [], []\n",
    "    for u, g in df.groupby('user_id', sort=False):\n",
    "        if len(g) < min_hist: \n",
    "            continue\n",
    "        t = int(len(g) * train_ratio)\n",
    "        if t == 0 or len(g) - t == 0:\n",
    "            continue\n",
    "        train.append(g.iloc[:t]); test.append(g.iloc[t:])\n",
    "    return pd.concat(train), pd.concat(test)\n",
    "\n",
    "train_df, test_df = chrono_split_per_user(reviews_df, 0.8, 3)\n",
    "print(\"train:\", train_df.shape, \"test:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44335, 3708)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ID encoding (fit on TRAIN only) + cold-start filtering for TEST\n",
    "le_user = LabelEncoder()\n",
    "le_item = LabelEncoder()\n",
    "\n",
    "train_df[\"user_idx\"] = le_user.fit_transform(train_df[\"user_id\"].values)\n",
    "train_df[\"item_idx\"] = le_item.fit_transform(train_df[\"gmap_id\"].values)\n",
    "\n",
    "seen_users = set(train_df[\"user_id\"])\n",
    "seen_items = set(train_df[\"gmap_id\"])\n",
    "\n",
    "test_df = test_df[test_df[\"user_id\"].isin(seen_users) & test_df[\"gmap_id\"].isin(seen_items)].copy()\n",
    "test_df[\"user_idx\"] = le_user.transform(test_df[\"user_id\"].values)\n",
    "test_df[\"item_idx\"] = le_item.transform(test_df[\"gmap_id\"].values)\n",
    "\n",
    "n_users = train_df[\"user_idx\"].nunique()\n",
    "n_items = train_df[\"item_idx\"].nunique()\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Hetero Graph (users & restaurants)\n",
    "Construct the core **user–restaurant graph** that the GNN will learn from.\n",
    "- Each **user node** represents an individual reviewer (no explicit features yet; only an ID embedding).\n",
    "- Each **restaurant node** includes a small numeric feature vector containing:\n",
    "  - `avg_rating`: the restaurant’s average rating (quality signal)\n",
    "  - `num_of_reviews`: number of reviews (popularity signal)\n",
    "  - `price_level`: encoded from `$`, `$$`, etc. (cost signal)\n",
    "- Each **edge** `(user → restaurant)` corresponds to a past review or interaction, with a reverse edge added for message passing (`restaurant → user`).\n",
    " \n",
    "We use only these three features initially because they are **dense, reliable, and numeric**, allowing the model to focus on learning the **structural relationships** between users and restaurants.\n",
    " \n",
    "Other fields (e.g. `category`, `description`, `latitude`, `MISC`) are intentionally excluded for now since they are sparse, text-heavy, or require additional preprocessing.  \n",
    "Once the base GNN is stable, these richer attributes can be incrementally integrated either as additional node features or new node types (e.g. category, aspect, or location nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ num_nodes=44335 },\n",
       "  restaurant={\n",
       "    num_nodes=3708,\n",
       "    x=[3708, 3],\n",
       "  },\n",
       "  (user, interacts, restaurant)={ edge_index=[2, 224017] },\n",
       "  (restaurant, rev_interacts, user)={ edge_index=[2, 224017] }\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple item features from metadata\n",
    "def coerce_price(p):\n",
    "    if pd.isna(p): \n",
    "        return 0\n",
    "    return int(str(p).count('$'))\n",
    "\n",
    "items_small = items_df[[\"gmap_id\",\"avg_rating\",\"num_of_reviews\",\"price\"]].copy()\n",
    "items_small[\"price_level\"] = items_small[\"price\"].apply(coerce_price)\n",
    "items_small = items_small.drop(columns=[\"price\"]).fillna({\"avg_rating\":0.0,\"num_of_reviews\":0,\"price_level\":0})\n",
    "\n",
    "# keep only items in train index space\n",
    "items_small = items_small[items_small[\"gmap_id\"].isin(seen_items)].copy()\n",
    "items_small[\"item_idx\"] = le_item.transform(items_small[\"gmap_id\"].values)\n",
    "items_small = items_small.set_index(\"item_idx\").sort_index()\n",
    "\n",
    "item_feats = torch.tensor(items_small[[\"avg_rating\",\"num_of_reviews\",\"price_level\"]].values, dtype=torch.float)\n",
    "\n",
    "# edges (train interactions)\n",
    "ui = torch.tensor(train_df[[\"user_idx\",\"item_idx\"]].values.T, dtype=torch.long)\n",
    "\n",
    "data = HeteroData()\n",
    "data[\"user\"].num_nodes = n_users\n",
    "data[\"restaurant\"].num_nodes = n_items\n",
    "data[\"restaurant\"].x = item_feats  # users: ID-emb only for v1\n",
    "\n",
    "# both directions for message passing\n",
    "data[\"user\",\"interacts\",\"restaurant\"].edge_index = ui\n",
    "data[\"restaurant\",\"rev_interacts\",\"user\"].edge_index = ui.flip(0)\n",
    "\n",
    "# ----- Aspect hooks (add later when ABSA aggregates are ready) -----\n",
    "# data[\"aspect\"].x = torch.eye(8)\n",
    "# data[\"user\",\"expresses\",\"aspect\"].edge_index = ua_edge_index\n",
    "# data[\"aspect\",\"rev_expresses\",\"user\"].edge_index = ua_edge_index.flip(0)\n",
    "# data[\"restaurant\",\"has\",\"aspect\"].edge_index = ia_edge_index\n",
    "# data[\"aspect\",\"rev_has\",\"restaurant\"].edge_index = ia_edge_index.flip(0)\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "data = data.to(device)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44335, 44304)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos = train_df.groupby('user_idx')['item_idx'].apply(set).to_dict()\n",
    "test_pos  = test_df.groupby('user_idx')['item_idx'].apply(list).to_dict()\n",
    "test_users = sorted(test_pos.keys())\n",
    "len(train_pos), len(test_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: HetRecGNN (HeteroConv with GCNConv per relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HetRecGNN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, hidden=64, layers=2, use_item_feats=True):\n",
    "        super().__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.use_item_feats = use_item_feats\n",
    "\n",
    "        # ID embeddings\n",
    "        self.user_emb = nn.Embedding(n_users, hidden)\n",
    "        self.item_emb = nn.Embedding(n_items, hidden)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "\n",
    "        # fuse basic item metadata (optional)\n",
    "        self.item_feat_mlp = None\n",
    "        if use_item_feats and data[\"restaurant\"].x is not None:\n",
    "            in_dim = data[\"restaurant\"].x.size(-1)\n",
    "            self.item_feat_mlp = nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden), nn.ReLU(), nn.Linear(hidden, hidden)\n",
    "            )\n",
    "\n",
    "        # relation-specific convs\n",
    "        self.convs = nn.ModuleList([\n",
    "            HeteroConv({\n",
    "                (\"user\",\"interacts\",\"restaurant\"):     GCNConv((-1, -1), hidden),\n",
    "                (\"restaurant\",\"rev_interacts\",\"user\"): GCNConv((-1, -1), hidden),\n",
    "                # add aspect relations here later:\n",
    "                # (\"user\",\"expresses\",\"aspect\"):         GCNConv((-1,-1), hidden),\n",
    "                # (\"aspect\",\"rev_expresses\",\"user\"):     GCNConv((-1,-1), hidden),\n",
    "                # (\"restaurant\",\"has\",\"aspect\"):         GCNConv((-1,-1), hidden),\n",
    "                # (\"aspect\",\"rev_has\",\"restaurant\"):     GCNConv((-1,-1), hidden),\n",
    "            }, aggr=\"sum\")\n",
    "            for _ in range(layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, data: HeteroData):\n",
    "        x = {\n",
    "            \"user\": self.user_emb.weight,\n",
    "            \"restaurant\": self.item_emb.weight\n",
    "        }\n",
    "        if self.item_feat_mlp is not None:\n",
    "            x[\"restaurant\"] = x[\"restaurant\"] + self.item_feat_mlp(data[\"restaurant\"].x)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, data.edge_index_dict)\n",
    "            x = {k: F.relu(v) for k, v in x.items()}\n",
    "        return x[\"user\"], x[\"restaurant\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def dot_predict(user_z, item_z, pairs):\n",
    "        u = user_z[pairs[0]]; i = item_z[pairs[1]]\n",
    "        return (u * i).sum(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
