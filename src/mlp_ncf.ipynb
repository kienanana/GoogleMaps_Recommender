{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e244b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.14/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.14/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.11/3.11.14/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 701, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 469, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 379, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 899, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 471, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 632, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/6l/0dr5mry10lddprxw6f8y9s3w0000gn/T/ipykernel_14991/1743760388.py\", line 9, in <module>\n",
      "    import torch\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/kienanana/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d028ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_in_chunks(file_path, chunk_size=10000):\n",
    "    \"\"\"Read large JSON file in chunks\"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        chunk = []\n",
    "        for i, line in enumerate(file):\n",
    "            chunk.append(line)\n",
    "            \n",
    "            if (i + 1) % chunk_size == 0:\n",
    "                chunk_df = pd.read_json('\\n'.join(chunk), lines=True)\n",
    "                chunks.append(chunk_df)\n",
    "                chunk = []  \n",
    "        \n",
    "        # process remaining lines\n",
    "        if chunk:\n",
    "            chunk_df = pd.read_json('\\n'.join(chunk), lines=True)\n",
    "            chunks.append(chunk_df)\n",
    "    \n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ec8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_file_path = \"../data/processed/sf-sampled-reviews.json\"\n",
    "reviews_df = read_json_in_chunks(reviews_file_path);\n",
    "restaurants_file_path = \"../data/processed/sf-restaurants.json\"\n",
    "restaurants_df = read_json_in_chunks(restaurants_file_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7adea361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411496, 6)\n",
      "(3721, 15)\n"
     ]
    }
   ],
   "source": [
    "print(reviews_df.shape)\n",
    "print(restaurants_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f0b3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 411496 entries, 0 to 411495\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   user_id  411496 non-null  float64\n",
      " 1   name     411496 non-null  object \n",
      " 2   time     411496 non-null  int64  \n",
      " 3   rating   411496 non-null  int64  \n",
      " 4   text     220550 non-null  object \n",
      " 5   gmap_id  411496 non-null  object \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 18.8+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef14daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load aspect features (Parquet) ---\n",
    "from pathlib import Path\n",
    "\n",
    "FEAT_DIR = Path(\"../data/processed/features/aspects\")\n",
    "user_aspects = pd.read_parquet(FEAT_DIR / \"user_aspect_prefs.parquet\")\n",
    "item_aspects = pd.read_parquet(FEAT_DIR / \"item_aspect_prefs.parquet\")\n",
    "\n",
    "user_aspects[\"user_id\"] = user_aspects[\"user_id\"].astype(str)\n",
    "item_aspects[\"gmap_id\"] = item_aspects[\"gmap_id\"].astype(str)\n",
    "reviews_df[\"user_id\"] = reviews_df[\"user_id\"].astype(str)\n",
    "reviews_df[\"gmap_id\"] = reviews_df[\"gmap_id\"].astype(str)\n",
    "\n",
    "# select aspect columns\n",
    "ASPECTS = [\"food\",\"service\",\"price\",\"ambience\",\"cleanliness\",\"portion\",\"wait_time\",\"location\"]\n",
    "U_COLS = [\"user_id\",\"n_reviews\"] + [f\"{a}_pref\" for a in ASPECTS]\n",
    "I_COLS = [\"gmap_id\",\"n_reviews\"] + [f\"{a}_pref\" for a in ASPECTS]\n",
    "\n",
    "user_aspects = user_aspects[U_COLS].rename(columns={\"n_reviews\":\"u_n_reviews\", **{f\"{a}_pref\":f\"u_{a}\" for a in ASPECTS}})\n",
    "item_aspects = item_aspects[I_COLS].rename(columns={\"n_reviews\":\"i_n_reviews\", **{f\"{a}_pref\":f\"i_{a}\" for a in ASPECTS}})\n",
    "\n",
    "# join onto interactions\n",
    "reviews_df = reviews_df.merge(user_aspects, on=\"user_id\", how=\"left\")\n",
    "reviews_df = reviews_df.merge(item_aspects, on=\"gmap_id\", how=\"left\")\n",
    "\n",
    "# fill missing (cold-start) with zeros\n",
    "for a in ASPECTS:\n",
    "    reviews_df[f\"u_{a}\"] = reviews_df[f\"u_{a}\"].fillna(0.0)\n",
    "    reviews_df[f\"i_{a}\"] = reviews_df[f\"i_{a}\"].fillna(0.0)\n",
    "reviews_df[\"u_n_reviews\"] = reviews_df[\"u_n_reviews\"].fillna(0).astype(np.int32)\n",
    "reviews_df[\"i_n_reviews\"] = reviews_df[\"i_n_reviews\"].fillna(0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8526334c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users (U): 131972\n",
      "Restaurants (I): 3721\n",
      "Interactions (N): 411496\n",
      "Data Sparsity: 0.08%\n"
     ]
    }
   ],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "restaurant_encoder = LabelEncoder()\n",
    "\n",
    "reviews_df[\"user_encoded\"] = user_encoder.fit_transform(reviews_df[\"user_id\"])\n",
    "reviews_df[\"restaurant_encoded\"] = restaurant_encoder.fit_transform(reviews_df[\"gmap_id\"])\n",
    "\n",
    "reviews_df[\"label\"] = reviews_df[\"rating\"]\n",
    "reviews_df[\"label_binary\"] = (reviews_df[\"rating\"] >= 4).astype(int)\n",
    "\n",
    "## Dataset Sparsity () counts-only\n",
    "U = reviews_df[\"user_encoded\"].nunique()\n",
    "I = reviews_df[\"restaurant_encoded\"].nunique()\n",
    "N = len(reviews_df)\n",
    "sparsity = N / (U * I)\n",
    "\n",
    "reviews_df['timestamp'] = pd.to_datetime(reviews_df['time'])\n",
    "reviews_df = reviews_df.sort_values('timestamp')\n",
    "\n",
    "split_idx = int(len(reviews_df) * 0.8)\n",
    "train_df = reviews_df.iloc[:split_idx]\n",
    "test_df = reviews_df.iloc[split_idx:]\n",
    "\n",
    "print(f\"Users (U): {U}\")\n",
    "print(f\"Restaurants (I): {I}\")\n",
    "print(f\"Interactions (N): {N}\")\n",
    "print(f\"Data Sparsity: {sparsity*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a76856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes=[128, 256, 512, 256, 64]\n",
    "dropout_sizes = [0.2,0.3,0.4,0.3,0.2]\n",
    "\n",
    "class MLPBlock(nn.Module):\n",
    "    \"\"\"A reusable fully-connected block with optional BatchNorm, ReLU, and Dropout.\"\"\"\n",
    "    def __init__(self, in_dim, out_dim, dropout=0.0, use_bn=True):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, out_dim)]\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm1d(out_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        if dropout > 0:\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class NCFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_restaurants, embedding_dim=64, extra_dim=0):\n",
    "        super(NCFModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_restaurants, embedding_dim)\n",
    "\n",
    "        mlp_layers = []\n",
    "        input_dim = embedding_dim * 2 + extra_dim\n",
    "        for i in range(len(layer_sizes)):\n",
    "            hidden_dim = layer_sizes[i]\n",
    "            dropout = dropout_sizes[i]\n",
    "            mlp_layers.append(MLPBlock(input_dim, hidden_dim, dropout=dropout))\n",
    "            input_dim = hidden_dim\n",
    "        mlp_layers.append(nn.Linear(input_dim, 1))  # output layer\n",
    "        self.mlp=nn.Sequential(*mlp_layers)\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "\n",
    "\n",
    "    def forward(self, user, item, side_feats=None):\n",
    "        u = self.user_embedding(user)\n",
    "        i = self.item_embedding(item)\n",
    "        x = torch.cat([u, i], dim=1)\n",
    "        if side_feats is not None:\n",
    "            x = torch.cat([x, side_feats], dim=1)\n",
    "        logits = self.mlp(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a627c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FEATS = [f\"u_{a}\" for a in ASPECTS] + [\"u_n_reviews\"]\n",
    "ITEM_FEATS = [f\"i_{a}\" for a in ASPECTS] + [\"i_n_reviews\"]\n",
    "SIDE_FEATS = USER_FEATS + ITEM_FEATS  # 8+1 + 8+1 = 18 dims\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, dataframe, use_side_feats=True):\n",
    "        self.use_side_feats = use_side_feats\n",
    "        self.users = torch.tensor(dataframe[\"user_encoded\"].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(dataframe[\"restaurant_encoded\"].values, dtype=torch.long)\n",
    "        self.labels = torch.tensor(dataframe[\"label\"].values, dtype=torch.float32)\n",
    "        if use_side_feats:\n",
    "            X = dataframe[SIDE_FEATS].astype(np.float32).values\n",
    "            self.x = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.use_side_feats:\n",
    "            return self.users[idx], self.items[idx], self.x[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = ReviewsDataset(train_df)\n",
    "test_dataset = ReviewsDataset(test_df)\n",
    "\n",
    "USE_SIDE_FEATS = True\n",
    "train_dataset = ReviewsDataset(train_df, use_side_feats=USE_SIDE_FEATS)\n",
    "test_dataset  = ReviewsDataset(test_df,  use_side_feats=USE_SIDE_FEATS)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    if USE_SIDE_FEATS:\n",
    "        u,i,x,y = zip(*batch)\n",
    "        return (torch.stack(u), torch.stack(i), torch.stack(x), torch.stack(y))\n",
    "    else:\n",
    "        u,i,y = zip(*batch)\n",
    "        return (torch.stack(u), torch.stack(i), torch.stack(y))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=1028, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca530b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131972 3721\n"
     ]
    }
   ],
   "source": [
    "num_users = reviews_df[\"user_encoded\"].nunique()\n",
    "num_restaurants = reviews_df[\"restaurant_encoded\"].nunique()\n",
    "print(num_users, num_restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58c0f4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCFModel(\n",
      "  (user_embedding): Embedding(131972, 64)\n",
      "  (item_embedding): Embedding(3721, 64)\n",
      "  (mlp): Sequential(\n",
      "    (0): MLPBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (1): MLPBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (2): MLPBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.4, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (3): MLPBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (4): MLPBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (5): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m training_loss = \u001b[32m0\u001b[39m\n\u001b[32m     15\u001b[39m total_samples = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u, i, r \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     17\u001b[39m     u, i, r = u.to(device), i.to(device), r.to(device)\n\u001b[32m     19\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "## original training cell\n",
    "model = NCFModel(num_users, num_restaurants)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001, weight_decay=1e-5)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(20):\n",
    "\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    total_samples = 0\n",
    "    for u, i, r in train_loader:\n",
    "        u, i, r = u.to(device), i.to(device), r.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(u, i).squeeze(-1)\n",
    "\n",
    "        loss = criterion(logits, r)\n",
    "        training_loss += loss.item() * r.size(0)\n",
    "        total_samples += r.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_training_loss = training_loss / total_samples\n",
    "    train_losses.append(average_training_loss)\n",
    "    training_rmse = np.sqrt(average_training_loss)\n",
    "\n",
    "    if average_training_loss < 1.0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 2e-5  \n",
    "\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    val_loss = 0\n",
    "    all_preds, all_labels =  [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for u, i, r in test_loader:\n",
    "            u, i, r = u.to(device), i.to(device), r.to(device)\n",
    "            logits = model(u,i).squeeze(-1)\n",
    "\n",
    "            all_preds.extend(logits.cpu().numpy())\n",
    "            all_labels.extend(r.cpu().numpy())\n",
    "\n",
    "            predictions = (logits >= 4).int()\n",
    "            actual = (r>= 4).int()\n",
    "            new_correct = (predictions == actual).sum().item()\n",
    "            num_correct += new_correct\n",
    "\n",
    "            loss = criterion(logits, r)\n",
    "            val_loss += loss.item()*r.size(0)\n",
    "\n",
    "    average_val_loss = val_loss/len(all_preds)\n",
    "    val_rmse = np.sqrt(average_val_loss)\n",
    "    val_losses.append(average_val_loss)\n",
    "    accuracy = num_correct / len(all_labels)\n",
    "\n",
    "\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"Training Loss: {average_training_loss:.4f}, Validation Loss: {average_val_loss:.4f}\")\n",
    "    print(f\"Training RMSE: {training_rmse:.4f}, Validation RMSE: {val_rmse:.4f}\")\n",
    "    print(f\"Validation Accuracy: {100*accuracy:.4f}%\")\n",
    "\n",
    "\n",
    "# Plotting of training and validation loss curves\n",
    "plt.plot(range(1, 21), train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(range(1, 21), val_losses, label='Validation Loss', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eaa5fa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "Epoch 1:\n",
      "Training Loss: 9.8849, Validation Loss: 4.8018\n",
      "Training RMSE: 3.1440, Validation RMSE: 2.1913\n",
      "Validation Accuracy: 14.3840%\n",
      "(early-stop) best_val=4.8018 | patience=0/3\n",
      "====================================================================================\n",
      "Epoch 2:\n",
      "Training Loss: 2.4780, Validation Loss: 1.4429\n",
      "Training RMSE: 1.5742, Validation RMSE: 1.2012\n",
      "Validation Accuracy: 14.5468%\n",
      "(early-stop) best_val=1.4429 | patience=0/3\n",
      "====================================================================================\n",
      "Epoch 3:\n",
      "Training Loss: 1.2458, Validation Loss: 0.9807\n",
      "Training RMSE: 1.1162, Validation RMSE: 0.9903\n",
      "Validation Accuracy: 81.3135%\n",
      "(early-stop) best_val=0.9807 | patience=0/3\n",
      "====================================================================================\n",
      "Epoch 4:\n",
      "Training Loss: 1.0949, Validation Loss: 0.9823\n",
      "Training RMSE: 1.0464, Validation RMSE: 0.9911\n",
      "Validation Accuracy: 73.8809%\n",
      "(early-stop) best_val=0.9807 | patience=1/3\n",
      "====================================================================================\n",
      "Epoch 5:\n",
      "Training Loss: 0.9631, Validation Loss: 0.9757\n",
      "Training RMSE: 0.9814, Validation RMSE: 0.9878\n",
      "Validation Accuracy: 74.0826%\n",
      "(early-stop) best_val=0.9757 | patience=0/3\n",
      "====================================================================================\n",
      "Epoch 6:\n",
      "Training Loss: 0.8424, Validation Loss: 0.9917\n",
      "Training RMSE: 0.9178, Validation RMSE: 0.9959\n",
      "Validation Accuracy: 74.6853%\n",
      "(early-stop) best_val=0.9757 | patience=1/3\n",
      "====================================================================================\n",
      "Epoch 7:\n",
      "Training Loss: 0.8172, Validation Loss: 0.9854\n",
      "Training RMSE: 0.9040, Validation RMSE: 0.9927\n",
      "Validation Accuracy: 74.5273%\n",
      "(early-stop) best_val=0.9757 | patience=2/3\n",
      "====================================================================================\n",
      "Epoch 8:\n",
      "Training Loss: 0.7942, Validation Loss: 0.9977\n",
      "Training RMSE: 0.8912, Validation RMSE: 0.9989\n",
      "Validation Accuracy: 74.1883%\n",
      "(early-stop) best_val=0.9757 | patience=3/3\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (8,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     96\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Plotting of training and validation loss curves\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m21\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTraining Loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mblue\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m plt.plot(\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m21\u001b[39m), val_losses, label=\u001b[33m'\u001b[39m\u001b[33mValidation Loss\u001b[39m\u001b[33m'\u001b[39m, color=\u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    101\u001b[39m plt.legend()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/matplotlib/pyplot.py:3838\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   3830\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.plot)\n\u001b[32m   3831\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot\u001b[39m(\n\u001b[32m   3832\u001b[39m     *args: \u001b[38;5;28mfloat\u001b[39m | ArrayLike | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3836\u001b[39m     **kwargs,\n\u001b[32m   3837\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[32m-> \u001b[39m\u001b[32m3838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3839\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3842\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/matplotlib/axes/_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SCHOOL/Y3S1/BT4222/PROJECT/.venv/lib/python3.11/site-packages/matplotlib/axes/_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (20,) and (8,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### NEW TRAINING CELL WITH FEATURES\n",
    "\n",
    "extra_dim = len(SIDE_FEATS) if USE_SIDE_FEATS else 0\n",
    "model = NCFModel(num_users, num_restaurants, embedding_dim=64, extra_dim=extra_dim)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "PATIENCE = 3                    \n",
    "best_val = float(\"inf\")\n",
    "patience_ctr = 0\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # CHANGED: unpack depending on USE_SIDE_FEATS\n",
    "        if USE_SIDE_FEATS:\n",
    "            u, i, x, r = batch\n",
    "            u, i, x, r = u.to(device), i.to(device), x.to(device), r.to(device)\n",
    "            logits = model(u, i, side_feats=x).squeeze(-1)   \n",
    "        else:\n",
    "            u, i, r = batch\n",
    "            u, i, r = u.to(device), i.to(device), r.to(device)\n",
    "            logits = model(u, i).squeeze(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(logits, r)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item() * r.size(0)\n",
    "        total_samples += r.size(0)\n",
    "\n",
    "    average_training_loss = training_loss / total_samples\n",
    "    train_losses.append(average_training_loss)\n",
    "    training_rmse = np.sqrt(average_training_loss)\n",
    "\n",
    "    if average_training_loss < 1.0:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = 2e-5\n",
    "\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    val_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # CHANGED: same branching in eval\n",
    "            if USE_SIDE_FEATS:\n",
    "                u, i, x, r = batch\n",
    "                u, i, x, r = u.to(device), i.to(device), x.to(device), r.to(device)\n",
    "                logits = model(u, i, side_feats=x).squeeze(-1)  \n",
    "            else:\n",
    "                u, i, r = batch\n",
    "                u, i, r = u.to(device), i.to(device), r.to(device)\n",
    "                logits = model(u, i).squeeze(-1)\n",
    "\n",
    "            all_preds.extend(logits.cpu().tolist())\n",
    "            all_labels.extend(r.cpu().tolist())\n",
    "\n",
    "            predictions = (logits >= 4).int()\n",
    "            actual = (r >= 4).int()\n",
    "            num_correct += (predictions == actual).sum().item()\n",
    "\n",
    "            val_loss += criterion(logits, r).item() * r.size(0)\n",
    "\n",
    "    average_val_loss = val_loss / len(all_preds)\n",
    "    val_rmse = np.sqrt(average_val_loss)\n",
    "    val_losses.append(average_val_loss)\n",
    "    accuracy = num_correct / len(all_labels)\n",
    "\n",
    "    print(\"====================================================================================\")\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"Training Loss: {average_training_loss:.4f}, Validation Loss: {average_val_loss:.4f}\")\n",
    "    print(f\"Training RMSE: {training_rmse:.4f}, Validation RMSE: {val_rmse:.4f}\")\n",
    "    print(f\"Validation Accuracy: {100*accuracy:.4f}%\")\n",
    "    \n",
    "    if average_val_loss + 1e-6 < best_val:     \n",
    "        best_val = average_val_loss\n",
    "        patience_ctr = 0\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "\n",
    "    print(f\"(early-stop) best_val={best_val:.4f} | patience={patience_ctr}/{PATIENCE}\")\n",
    "    if patience_ctr >= PATIENCE:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Plotting of training and validation loss curves\n",
    "epochs_run = len(train_losses)\n",
    "\n",
    "plt.plot(range(1, epochs_run+1), train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(range(1, epochs_run+1), val_losses, label='Validation Loss', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e9b1ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'name', 'time', 'rating', 'text', 'gmap_id', 'u_n_reviews_x',\n",
       "       'u_food_x', 'u_service_x', 'u_price_x', 'u_ambience_x',\n",
       "       'u_cleanliness_x', 'u_portion_x', 'u_wait_time_x', 'u_location_x',\n",
       "       'i_n_reviews_x', 'i_food_x', 'i_service_x', 'i_price_x', 'i_ambience_x',\n",
       "       'i_cleanliness_x', 'i_portion_x', 'i_wait_time_x', 'i_location_x',\n",
       "       'u_n_reviews_y', 'u_food_y', 'u_service_y', 'u_price_y', 'u_ambience_y',\n",
       "       'u_cleanliness_y', 'u_portion_y', 'u_wait_time_y', 'u_location_y',\n",
       "       'i_n_reviews_y', 'i_food_y', 'i_service_y', 'i_price_y', 'i_ambience_y',\n",
       "       'i_cleanliness_y', 'i_portion_y', 'i_wait_time_y', 'i_location_y',\n",
       "       'u_n_reviews', 'u_food', 'u_service', 'u_price', 'u_ambience',\n",
       "       'u_cleanliness', 'u_portion', 'u_wait_time', 'u_location',\n",
       "       'i_n_reviews', 'i_food', 'i_service', 'i_price', 'i_ambience',\n",
       "       'i_cleanliness', 'i_portion', 'i_wait_time', 'i_location',\n",
       "       'user_encoded', 'restaurant_encoded', 'label', 'label_binary',\n",
       "       'timestamp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd05cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_ids_test = test_df['restaurant_encoded'].unique()\n",
    "restaurant_ids_train = train_df['restaurant_encoded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec5e1e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589\n",
      "3107\n"
     ]
    }
   ],
   "source": [
    "print(len(restaurant_ids_train))\n",
    "print(len(restaurant_ids_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0842f6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_binary\n",
       "1    271255\n",
       "0     57941\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label_binary'].value_counts()\n",
    "#total: 329196\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "031e9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"first_ncf_recommender.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac86196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
